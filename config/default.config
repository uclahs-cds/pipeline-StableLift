import nextflow.util.SysHelper

// Default inputs/parameters of the pipeline
params {
    max_cpus   = SysHelper.getAvailCpus()
    max_memory = SysHelper.getAvailMemory()
    min_cpus = 1
    min_memory = 1.MB

    dataset_id = ''
    blcds_registered_dataset = false

    ucla_cds = true
    docker_container_registry = "ghcr.io/uclahs-cds"

    // Docker images
    bcftools_version   = '1.20'
    bedtools_version   = '2.31.0'
    gatk_version       = '4.2.4.1'
    pipeval_version    = '5.0.0-rc.3'
    samtools_version   = '1.20'
    stablelift_version = 'x.x.x'    // FIXME

    docker_image_bcftools = "${-> params.docker_container_registry}/bcftools:${params.bcftools_version}"
    docker_image_bedtools = "${-> params.docker_container_registry}/bedtools:${params.bedtools_version}"
    docker_image_gatk = "broadinstitute/gatk:${params.gatk_version}"
    docker_image_pipeval = "${-> params.docker_container_registry}/pipeval:${params.pipeval_version}"
    docker_image_samtools = "${-> params.docker_container_registry}/samtools:${params.samtools_version}"
    docker_image_stablelift = "${-> params.docker_container_registry}/stablelift:${params.stablelift_version}"
}

// Process specific scope
process {
    // Process results are stored to local cache.
    // If pipeline is launched with the 'resume' option, existing cache results
    // will be used when available rather than re-executing processes
    cache = true

    // Forward process 'stdout' to shell terminal and, consequently, the log file
    echo = true
    executor = 'local'

    // Total amount of resources available to the pipeline
    cpus = params.max_cpus
    memory = params.max_memory
}

// Enable Docker and configure docker-related options like user and group IDs
docker {
    enabled = true
    // Pass user's UID/GID and group IDs to Docker
    uid_and_gid = "-u \$(id -u):\$(id -g)"
    all_group_ids = "\$(for i in `id --real --groups`; do echo -n \"--group-add=\$i \"; done)"

    runOptions = "${uid_and_gid} ${all_group_ids}"
}
